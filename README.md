# ğŸ§ª Python ETL Pipeline â€“ Local Simulation of Azure Data Lake to SQL

This project simulates an Azure Data Factory ETL pipeline using **Python** and **SQLite** locally. It reads CSV files from different folders, extracts date info from filenames, adds necessary columns, and loads data into a local SQLite database.

## ğŸ“ Folder Structure


## ğŸ“¦ Files

- `CUST_MSTR_YYYYMMDD.csv` â†’ Adds `Date` column from filename
- `master_child_export-YYYYMMDD.csv` â†’ Adds `Date` and `DateKey`
- `H_ECOM_ORDER.csv` â†’ Loaded as-is

## âœ… Features

- Simulates truncate-load pipeline
- Merges multiple CSVs
- Adds derived columns using filename
- Loads data to SQLite using Pandas

## ğŸ’¡ To Run

```bash
# Step 1: Run ETL
python etl_script.py

# Step 2: Load cleaned data into SQLite
python load_to_sqlite.py
